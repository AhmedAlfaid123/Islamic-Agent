{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_SrMwD37rDh"
      },
      "source": [
        "#**Ahmed Hassan Abbas**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "493c3b72",
        "outputId": "cea717ec-7dfc-4371-aa8c-00cf52a3b6e9"
      },
      "source": [
        "!pip install google-search-results"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting google-search-results\n",
            "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from google-search-results) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (2025.8.3)\n",
            "Building wheels for collected packages: google-search-results\n",
            "  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32010 sha256=27b27ef275ffd5e8eca2a0492bc7afc6744d44103b1bad65f7bf1702f3066a48\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/42/3e/aeb691b02cb7175ec70e2da04b5658d4739d2b41e5f73cd06f\n",
            "Successfully built google-search-results\n",
            "Installing collected packages: google-search-results\n",
            "Successfully installed google-search-results-2.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "XzEbd-c274X9",
        "outputId": "92a8425b-705e-4976-b366-b152d67e1dd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.27)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting langchain_google_genai\n",
            "  Downloading langchain_google_genai-2.1.9-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting chromadb\n",
            "  Downloading chromadb-1.0.16-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.39.0)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.72)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.9)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.10)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.42)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.2)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain_google_genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting google-ai-generativelanguage<0.7.0,>=0.6.18 (from langchain_google_genai)\n",
            "  Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.3.0)\n",
            "Collecting pybase64>=1.4.1 (from chromadb)\n",
            "  Downloading pybase64-1.4.2-cp311-cp311-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.35.0)\n",
            "Collecting posthog<6.0.0,>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.14.1)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.22.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.36.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.36.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.36.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.4)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.74.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.16.0)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.2.0-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.11.1)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.25.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.10.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.116.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.6.1)\n",
            "Requirement already satisfied: gradio-client==1.11.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.11.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.33.5 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.3)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.12.7)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.47.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.11.0->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.11.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (2.25.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (5.29.5)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (3.18.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (1.1.5)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.26.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.3.1)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.5.0)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.36.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.36.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.36.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.36.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.57b0 (from opentelemetry-sdk>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.57b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (4.9.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (0.6.1)\n",
            "Downloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_google_genai-2.1.9-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chromadb-1.0.16-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.6/19.6 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
            "Downloading kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.2.0-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.1/103.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.22.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.36.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.36.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.36.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.36.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.36.0-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.0/120.0 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.57b0-py3-none-any.whl (201 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.6/201.6 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybase64-1.4.2-cp311-cp311-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m95.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (453 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m453.1/453.1 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Building wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=eed95639cf1c53d60b921143ce1fdd31acb10dac7de0677961aced3bc55d8a09\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, filetype, durationpy, uvloop, python-dotenv, pybase64, overrides, opentelemetry-proto, mypy-extensions, mmh3, marshmallow, humanfriendly, httpx-sse, httptools, bcrypt, backoff, watchfiles, typing-inspect, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, pydantic-settings, opentelemetry-semantic-conventions, onnxruntime, kubernetes, dataclasses-json, opentelemetry-sdk, opentelemetry-exporter-otlp-proto-grpc, google-ai-generativelanguage, langchain_google_genai, chromadb, langchain_community\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed backoff-2.2.1 bcrypt-4.3.0 chromadb-1.0.16 coloredlogs-15.0.1 dataclasses-json-0.6.7 durationpy-0.10 filetype-1.2.0 google-ai-generativelanguage-0.6.18 httptools-0.6.4 httpx-sse-0.4.1 humanfriendly-10.0 kubernetes-33.1.0 langchain_community-0.3.27 langchain_google_genai-2.1.9 marshmallow-3.26.1 mmh3-5.2.0 mypy-extensions-1.1.0 onnxruntime-1.22.1 opentelemetry-api-1.36.0 opentelemetry-exporter-otlp-proto-common-1.36.0 opentelemetry-exporter-otlp-proto-grpc-1.36.0 opentelemetry-proto-1.36.0 opentelemetry-sdk-1.36.0 opentelemetry-semantic-conventions-0.57b0 overrides-7.7.0 posthog-5.4.0 pybase64-1.4.2 pydantic-settings-2.10.1 pypika-0.48.9 python-dotenv-1.1.1 typing-inspect-0.9.0 uvloop-0.21.0 watchfiles-1.1.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "0536cd2633cb4095bebb40f0fc03d434",
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install langchain langchain_community langchain_google_genai chromadb gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "u_VAOnSrUrD4",
        "outputId": "d00cec2a-8d14-484b-f90e-ccdd81156bdb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  KOTOB.zip\n",
            "   creating: KOTOB/\n",
            "  inflating: KOTOB/DOAA.json         \n",
            "  inflating: KOTOB/bukhari.json      \n",
            "  inflating: KOTOB/athkar.json       \n",
            "  inflating: KOTOB/aladab_almufrad.json  \n",
            "  inflating: KOTOB/ahmed.json        \n",
            "  inflating: KOTOB/abudawud.json     \n",
            "  inflating: KOTOB/tirmidhi.json     \n",
            "  inflating: KOTOB/nasai.json        \n",
            "  inflating: KOTOB/muslim.json       \n",
            "  inflating: KOTOB/malik.json        \n",
            "  inflating: KOTOB/ibnmajah.json     \n",
            "  inflating: KOTOB/darimi.json       \n"
          ]
        }
      ],
      "source": [
        "!unzip KOTOB.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEoZvREm70T0"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from google.colab import userdata\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain.schema import Document\n",
        "import os\n",
        "import json\n",
        "import requests\n",
        "import gradio as gr\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4dazL7suJMs"
      },
      "outputs": [],
      "source": [
        "def normalize_arabic(text: str) -> str:\n",
        "    if not text:\n",
        "        return \"\"\n",
        "    text = re.sub(r'[\\u0610-\\u061A\\u064B-\\u065F\\u06D6-\\u06ED]', '', text)\n",
        "    text = text.replace('\\u200f','').replace('\\u200e','')\n",
        "    text = text.strip()\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cx8riUX7_ah",
        "outputId": "acd242a4-b068-40ab-a19d-bc13b2ee836b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded from muslim.json\n",
            "Loaded from bukhari.json\n",
            "Loaded from malik.json\n",
            "Loaded from ahmed.json\n",
            "\n",
            " Total documents loaded: 17970\n"
          ]
        }
      ],
      "source": [
        "# ===================================\n",
        "# 2) Loading data, metadata\n",
        "# ===================================\n",
        "documents = []\n",
        "files_to_load = ['muslim.json', 'bukhari.json', 'malik.json', 'ahmed.json']\n",
        "\n",
        "for file_name in files_to_load:\n",
        "    file_path = os.path.join(file_name)\n",
        "    try:\n",
        "        if file_name.endswith('.json'):\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                data = json.load(f)\n",
        "            if 'hadiths' in data:\n",
        "                for hadith in data['hadiths']:\n",
        "                    if 'arabic' in hadith and hadith['arabic']:\n",
        "                        content = normalize_arabic(hadith['arabic'])\n",
        "                        metadata = {\n",
        "                            \"source\": file_name,\n",
        "                            \"id\": hadith.get('id'),\n",
        "                            \"bookId\": hadith.get('bookId'),\n",
        "                            \"chapterId\": hadith.get('chapterId')\n",
        "                        }\n",
        "                        documents.append(Document(page_content=content, metadata=metadata))\n",
        "            print(f\"Loaded from {file_name}\")\n",
        "\n",
        "        elif file_name.endswith('.txt'):\n",
        "            loader = TextLoader(file_path)\n",
        "            loaded_docs = loader.load()\n",
        "            for doc in loaded_docs:\n",
        "                doc.metadata[\"source\"] = file_name\n",
        "            documents.extend(loaded_docs)\n",
        "            print(f\"Loaded {len(loaded_docs)} from {file_name}\")\n",
        "\n",
        "        else:\n",
        "            print(f\"Skipping unsupported: {file_name}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error in {file_name}: {e}\")\n",
        "\n",
        "print(f\"\\n Total documents loaded: {len(documents)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "__f4JSaG8GeO",
        "outputId": "45324aff-fd83-42d8-9126-cdc61636f801"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original docs: 17970\n",
            "Split docs: 19185\n"
          ]
        }
      ],
      "source": [
        "# ===================================\n",
        "# 3) Create  Embeddings , VectorStore\n",
        "# ===================================\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "# embeddings = GoogleGenerativeAIEmbeddings(\n",
        "#     model=\"models/embedding-001\",\n",
        "#     google_api_key=userdata.get('GEMINI_API_KEY')\n",
        "# )\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"intfloat/multilingual-e5-base\")\n",
        "\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=100)\n",
        "split_documents = text_splitter.split_documents(documents)\n",
        "\n",
        "print(f\"Original docs: {len(documents)}\")\n",
        "print(f\"Split docs: {len(split_documents)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTD_cF9qaEMq",
        "outputId": "0c909c52-07e4-444d-a391-6535268dc975"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/tmp/ipython-input-2668280718.py:6: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
            "  vectorstore.persist()\n"
          ]
        }
      ],
      "source": [
        "vectorstore = Chroma.from_documents(\n",
        "    documents=split_documents,\n",
        "    embedding=embeddings,\n",
        "    persist_directory=\"./chroma_db\"\n",
        ")\n",
        "vectorstore.persist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Q7fIQ1P8Lgy"
      },
      "outputs": [],
      "source": [
        "# ===================================\n",
        "# 4) OpenRouter API connection\n",
        "# ===================================\n",
        "OPENROUTER_API_KEY = userdata.get('OPENROUTER_API_KEY')\n",
        "\n",
        "def call_openrouter_api(prompt):\n",
        "    response = requests.post(\n",
        "        url=\"https://openrouter.ai/api/v1/chat/completions\",\n",
        "        headers={\n",
        "            \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n",
        "            \"Content-Type\": \"application/json\"\n",
        "        },\n",
        "        json={\n",
        "            \"model\": \"openai/gpt-oss-120b\",\n",
        "            \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
        "            \"temperature\": 0.0,\n",
        "            \"max_tokens\": 900\n",
        "        }\n",
        "    )\n",
        "    data = response.json()\n",
        "    try:\n",
        "        return data['choices'][0]['message']['content']\n",
        "    except:\n",
        "        return response.json()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-eXnzR3bho_n",
        "outputId": "201d4d11-570e-4869-cc47-ba49c3b92723"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Hello! How can I assist you today?'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "call_openrouter_api(\"Hello\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ApBEIkj8O0e"
      },
      "outputs": [],
      "source": [
        "# ===================================\n",
        "# 5) Re-ranking\n",
        "# ===================================\n",
        "def rerank_results(query, docs, top_k=5):\n",
        "    scores = []\n",
        "    for doc in docs:\n",
        "        check_prompt = f\"\"\"السؤال: {query}\n",
        "النص: {doc.page_content}\n",
        "\n",
        "هل النص أعلاه يجيب على السؤال بشكل مباشر؟ أجب فقط بـ نعم أو لا.\n",
        "\"\"\"\n",
        "        ans = call_openrouter_api(check_prompt)\n",
        "        score = 1 if \"نعم\" in ans else 0\n",
        "        scores.append((doc, score))\n",
        "    sorted_docs = sorted(scores, key=lambda x: x[1], reverse=True)\n",
        "    return [doc for doc, _ in sorted_docs[:top_k]]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
        "import os\n",
        "\n",
        "SERPER_API_KEY = userdata.get('SERPER_API_KEY')"
      ],
      "metadata": {
        "id": "CJxW1pIAvkwC"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "Sgycdcp68TMd"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# 6) Searching with filtering by metadata, Re-ranking\n",
        "# ===================================================\n",
        "def ask_question_with_retrieval(query, book_filter=\"All Books\"):\n",
        "    search_kwargs = {\"k\": 50}\n",
        "    if book_filter != \"All Books\":\n",
        "        search_kwargs[\"filter\"] = {\"source\": book_filter}\n",
        "\n",
        "    retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs=search_kwargs)\n",
        "    initial_docs = retriever.get_relevant_documents(query)\n",
        "\n",
        "    top_docs = rerank_results(query, initial_docs, top_k=5)\n",
        "\n",
        "    context = \"\\n\".join([f\"Document from Vectorstore:\\n{doc.page_content}\" for doc in top_docs])\n",
        "\n",
        "    scraped_content = \"\"\n",
        "    scraped_source_url = \"\"\n",
        "\n",
        "    if SERPER_API_KEY:\n",
        "        print(\"Performing web search to supplement retrieval...\")\n",
        "        try:\n",
        "            search = GoogleSerperAPIWrapper(serper_api_key=SERPER_API_KEY)\n",
        "            search_results = search.results(query)\n",
        "            web_context = \"\"\n",
        "\n",
        "            if 'organic' in search_results:\n",
        "                for result in search_results['organic']:\n",
        "                    if result.get('link') and \"shamela.ws\" in result['link']:\n",
        "                        print(f\"Found trusted source: {result['link']}. Attempting to scrape.\")\n",
        "                        scrape_url = result['link']\n",
        "                        scrape_response = requests.post(\n",
        "                            url=\"https://serper.dev/api/scrape\",\n",
        "                            headers={\n",
        "                                \"X-API-KEY\": SERPER_API_KEY,\n",
        "                                \"Content-Type\": \"application/json\"\n",
        "                            },\n",
        "                            json={\"url\": scrape_url}\n",
        "                        )\n",
        "                        if scrape_response.status_code == 200:\n",
        "                            scrape_data = scrape_response.json()\n",
        "                            if 'article' in scrape_data and scrape_data['article']:\n",
        "                                scraped_content = normalize_arabic(scrape_data['article'])\n",
        "                                scraped_source_url = scrape_url\n",
        "                                print(\"Successfully scraped content from trusted source.\")\n",
        "                                break\n",
        "                            else:\n",
        "                                print(\"Scrape API returned no article content.\")\n",
        "                        else:\n",
        "                            print(f\"Scrape API failed with status code: {scrape_response.status_code}\")\n",
        "                            print(f\"Scrape API response: {scrape_response.text}\")\n",
        "\n",
        "                    web_context += f\"Web Search Result from {result.get('title')}:\\n{result.get('snippet')}\\n\\n\"\n",
        "\n",
        "            if scraped_content:\n",
        "                context = f\"Scraped Content from {scraped_source_url}:\\n{scraped_content}\\n\\n\" + context\n",
        "                print(\"Scraped content incorporated into context.\")\n",
        "            elif web_context:\n",
        "                context = context + \"\\n\\n\" + web_context\n",
        "                print(\"General web search results incorporated.\")\n",
        "            else:\n",
        "                print(\"Web search returned no relevant results.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Web search or scraping failed: {e}\")\n",
        "    else:\n",
        "        print(\"SERPER_API_KEY not available, skipping web search and scraping.\")\n",
        "\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "أنت وكيل مُتخصِّص في علم الحديث النبوي ومصادر المعلومات العامة. مهمتك:\n",
        "1) أجب على سؤال المستخدم بدقة وبوضوح باللغة العربية.\n",
        "2) استعمل فقط المعلومات الواردة في المقاطع (context) التالية عند تكوين الإجابة. لا تختلق مصادر جديدة.\n",
        "3) عندما تذكر معلومات من أي مقطع من Vectorstore ضع الاستشهاد بصيغة مربعات مثل: [المصدر | رقم الحديث | من اي باب  | حالة الحديث صحيح او حسن او ضعيف او مكذوب ].\n",
        "4) عندما تذكر معلومات من أي مقطع من Web Search Result اذكر المصدر بصيغة مربعات مثل: [موقع: عنوان الموقع].\n",
        "5) عندما تذكر معلومات من أي مقطع من Scraped Content اذكر المصدر بصيغة مربعات مثل: [المصدر المُستَخرَج: عنوان URL].\n",
        "6) إذا لم تكفِ المقاطع (من Vectorstore أو Web Search أو Scraped Content) للإجابة بصراحة اعترف بنقص الدليل وقل (لا أمتلك دليلاً كافياً في المصادر المتاحة).\n",
        "7) لا تُقدّم فتوى دينية جديدة — إن كان السؤال فقهيّا ادعُ المستخدم إلى الرجوع لعلماء متخصصين بعد عرض دلائل النص.\n",
        "8) اذكر نص الحديث عربيًا (إن اقتبست مباشرة من المقاطع من Vectorstore أو Scraped Content إذا كان حديثًا) بين علامتي اقتباس مزدوجة \"\" ثم الاستشهاد المناسب.\n",
        "9) النهاية: أدرج قائمة قصيرة \"المصادر المستخدمة\" بترتيب الاستشهادات، **مع التفرقة بين مصادر Vectorstore ومصادر Web Search ومصادر Scraped Content عن طريق تسمية كل قسم بوضوح (مثلاً: مصادر من قاعدة الأحاديث, مصادر من البحث عبر الويب, مصادر من المحتوى المُستَخرَج).**\n",
        "\n",
        "الآن أدناه المقاطع (context) المستخرجة من كتب الأحاديث والبحث عبر الويب والمحتوى المُستَخرَج:\n",
        "{context}\n",
        "\n",
        "السؤال: {query}\n",
        "\n",
        "أجب الآن باتباع التعليمات أعلاه.\n",
        "\"\"\"\n",
        "    answer = call_openrouter_api(prompt)\n",
        "    return {\"result\": answer, \"source_documents\": top_docs, \"scraped_source\": scraped_source_url}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 685
        },
        "id": "L5L6qSXp7wI6",
        "outputId": "bc49de5e-7c24-4a52-f678-9bf097d56c91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1457770719.py:22: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chatbot = gr.Chatbot(label=\"Conversation\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://f835def62c6ee18c4b.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://f835def62c6ee18c4b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "\n",
        "books_list = [\"All Books\"] + files_to_load\n",
        "\n",
        "def chatbot_interface(user_message, selected_book, history):\n",
        "    if not user_message.strip():\n",
        "        return history + [[\"\", \"Please enter a question.\"]]\n",
        "\n",
        "    resp = ask_question_with_retrieval(user_message, selected_book)\n",
        "    answer = resp[\"result\"]\n",
        "\n",
        "    if \"Web Search Result\" in answer or (len(resp[\"source_documents\"]) < 5 and SERPER_API_KEY):\n",
        "         answer += \"\\n\\n*(Note: Web search was used to supplement the response.)*\"\n",
        "\n",
        "    history = history + [[user_message, answer]]\n",
        "    return history\n",
        "\n",
        "with gr.Blocks() as iface:\n",
        "    gr.Markdown(\"# Hadith Chatbot\")\n",
        "\n",
        "    with gr.Row():\n",
        "        selected_book = gr.Dropdown(choices=books_list, value=\"All Books\", label=\"Select Book\")\n",
        "\n",
        "    chatbot = gr.Chatbot(label=\"Conversation\")\n",
        "    msg = gr.Textbox(placeholder=\"Type your message here...\", label=\"Your Message\")\n",
        "    clear = gr.Button(\"Clear Chat\")\n",
        "\n",
        "    msg.submit(chatbot_interface, [msg, selected_book, chatbot], chatbot)\n",
        "    clear.click(lambda: None, None, chatbot)\n",
        "\n",
        "iface.launch(inline=True)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKDJyye-xHBP",
        "outputId": "5f0acea9-00dc-4913-af7b-f6c4fa985281"
      },
      "source": [
        "test_query_2 = \"ما هو حكم ترك الصلاة؟\"\n",
        "print(f\"Testing query: {test_query_2}\")\n",
        "response_2 = ask_question_with_retrieval(test_query_2)\n",
        "\n",
        "print(\"\\nResponse from the chatbot:\")\n",
        "print(response_2['result'])\n",
        "print(\"\\nSource documents (from vectorstore):\")\n",
        "for i, doc in enumerate(response_2['source_documents']):\n",
        "    print(f\"Document {i+1}:\")\n",
        "    print(f\"  Content: {doc.page_content}\")\n",
        "    print(f\"  Source: {doc.metadata.get('source', 'N/A')}\")\n",
        "    print(f\"  ID: {doc.metadata.get('id', 'N/A')}\")\n",
        "    print(f\"  Book ID: {doc.metadata.get('bookId', 'N/A')}\")\n",
        "    print(f\"  Chapter ID: {doc.metadata.get('chapterId', 'N/A')}\")"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing query: ما هو حكم ترك الصلاة؟\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing web search to supplement retrieval...\n",
            "General web search results incorporated.\n",
            "\n",
            "Response from the chatbot:\n",
            "**حكم ترك الصلاة في الإسلام**\n",
            "\n",
            "1. **الاجتهاد السائد (الإجماع)**\n",
            "   - أغلب العلماء يرون أن من ترك الصلاة **جاحدًا لوجوبها** يُعدُّ كافرًا. وهذا ما يُستند إليه في الفتاوى الصادرة عن كبار العلماء مثل الشيخ ابن باز، حيث يذكر أن «من ترك الصلاة فهو كافر وإن كان غير جاحد لها» ويستند إلى قول النبي ﷺ في الحديث الصحيح *«العهد الذ …»* (الحديث يُستدل به في الفقه).  \n",
            "   - **[موقع: حكم تارك الصلاة عمداً تساهلاً وحكم تكفيره - موقع الشيخ ابن باز]**  \n",
            "   - **[موقع: ما حكم تارك الصلاة؟ - موقع الشيخ ابن باز]**  \n",
            "   - **[موقع: حكم الصلاة وأهميتها - موقع الشيخ ابن باز]**  \n",
            "\n",
            "2. **الآراء المخالفة (عدم تكفيره)**\n",
            "   - **المالكي والشافعي**: يرى كلٌّ منهما أن ترك الصلاة لا يُكفر صاحبه، بل يُعاقب بالحد (الإعدام) إذا كان تركًا متعمدًا.  \n",
            "     - **[موقع: عقوبة تارك الصلاة في الدنيا والآخرة - إسلام ويب]**  \n",
            "   - **أبو حنيفة**: يقرّ أن من ترك الصلاة يُحجز (يُسجن) حتى يُصلِّي، ولا يُكفر.  \n",
            "     - **[موقع: عقوبة تارك الصلاة في الدنيا والآخرة - إسلام ويب]**  \n",
            "   - **الشيخ عبدالعزيز بن باز** (مقتبس في بعض المواقع) يوضح أن «ر، ومن يترك أحد أركان الإيمان (الصلاة) بجهل أو تهاون لا يُكفر، وإنما يُعَدُّ من المرتكبين للمعصية.  \n",
            "     - **[موقع: ما حكم تارك الصلاة؟ - موقع الشيخ ابن باز]**  \n",
            "\n",
            "3. **رأي الشيخ ابن عثيمين**\n",
            "   - يبيّن أن ترك الصلاة لا يُكفر دائمًا؛ فالمقصد هو الجحد الواضح لوجوبها. إذا كان الشخص يتركها لتكاسل أو سهو، فليس كافرًا، وإنما يُعَدُّ من\n",
            "\n",
            "Source documents (from vectorstore):\n",
            "Document 1:\n",
            "  Content: الله عليه وسلم \" لا يصادفها عبد مسلم وهو يصلي \" . وتلك الساعة ساعة لا يصلى فيها فقال عبد الله بن سلام ألم يقل رسول الله صلى الله عليه وسلم \" من جلس مجلسا ينتظر الصلاة فهو في صلاة حتى يصلي \" . قال أبو هريرة فقلت بلى . قال فهو ذلك .\n",
            "  Source: malik.json\n",
            "  ID: 34419\n",
            "  Book ID: 7\n",
            "  Chapter ID: 5\n",
            "Document 2:\n",
            "  Content: حدثنا محمد بن عبد الله بن نمير، حدثنا أبي، حدثنا بدر بن عثمان، حدثنا أبو بكر بن أبي موسى، عن أبيه، عن رسول الله صلى الله عليه وسلم أنه أتاه سائل يسأله عن مواقيت الصلاة فلم يرد عليه شيئا - قال - فأقام الفجر حين انشق الفجر والناس لا يكاد يعرف بعضهم بعضا ثم أمره فأقام بالظهر حين زالت الشمس والقائل يقول قد انتصف النهار وهو كان أعلم منهم ثم أمره فأقام بالعصر والشمس مرتفعة ثم أمره فأقام بالمغرب حين وقعت الشمس ثم أمره فأقام العشاء حين غاب الشفق ثم أخر الفجر من الغد حتى انصرف منها والقائل يقول قد طلعت الشمس أو كادت ثم أخر الظهر حتى كان قريبا من وقت العصر بالأمس ثم أخر العصر حتى انصرف منها والقائل يقول قد احمرت الشمس ثم أخر المغرب حتى كان عند سقوط الشفق ثم أخر العشاء حتى كان ثلث الليل الأول ثم أصبح فدعا السائل فقال \" الوقت بين هذين \" .\n",
            "  Source: muslim.json\n",
            "  ID: 8566\n",
            "  Book ID: 2\n",
            "  Chapter ID: 5\n",
            "Document 3:\n",
            "  Content: حدثني يحيى، عن مالك، عن حميد بن قيس، وثور بن زيد الديلي، أنهما أخبراه عن رسول الله صلى الله عليه وسلم وأحدهما يزيد في الحديث على صاحبه أن رسول الله صلى الله عليه وسلم رأى رجلا قائما في الشمس فقال \" ما بال هذا \" . فقالوا نذر أن لا يتكلم ولا يستظل من الشمس ولا يجلس ويصوم . فقال رسول الله صلى الله عليه وسلم \" مروه فليتكلم وليستظل وليجلس وليتم صيامه \" . قال مالك ولم أسمع أن رسول الله صلى الله عليه وسلم أمره بكفارة وقد أمره رسول الله صلى الله عليه وسلم أن يتم ما كان لله طاعة ويترك ما كان لله معصية .\n",
            "  Source: malik.json\n",
            "  ID: 35240\n",
            "  Book ID: 7\n",
            "  Chapter ID: 22\n",
            "Document 4:\n",
            "  Content: عليه وسلم يأمره أن يصلي، فرفع أبو بكر ـ رضى الله عنه ـ يديه فحمد الله ورجع القهقرى وراءه حتى قام في الصف، فتقدم رسول الله صلى الله عليه وسلم فصلى للناس فلما فرغ أقبل على الناس فقال \" يا أيها الناس ما لكم حين نابكم شىء في الصلاة أخذتم في التصفيق، إنما التصفيق للنساء، من نابه شىء في صلاته فليقل سبحان الله. فإنه لا يسمعه أحد حين يقول سبحان الله إلا التفت، يا أبا بكر ما منعك أن تصلي للناس حين أشرت إليك \". فقال أبو بكر ـ رضى الله عنه ـ ما كان ينبغي لابن أبي قحافة أن يصلي بين يدى رسول الله صلى الله عليه وسلم.\n",
            "  Source: bukhari.json\n",
            "  ID: 1198\n",
            "  Book ID: 1\n",
            "  Chapter ID: 22\n",
            "Document 5:\n",
            "  Content: حدثنا إبراهيم بن المنذر، حدثنا محمد بن فليح، حدثنا أبي، عن هلال بن علي، عن عبد الرحمن بن أبي عمرة، عن أبي هريرة ـ رضى الله عنه ـ عن النبي صلى الله عليه وسلم قال \" إن أحدكم في صلاة ما دامت الصلاة تحبسه، والملائكة تقول اللهم اغفر له وارحمه. ما لم يقم من صلاته أو يحدث \".\n",
            "  Source: bukhari.json\n",
            "  ID: 3096\n",
            "  Book ID: 1\n",
            "  Chapter ID: 59\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}